<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>AILL â€” Acoustic Inter-agent Linguistic Link</title>
<link href="https://fonts.googleapis.com/css2?family=JetBrains+Mono:wght@300;400;500;600;700&family=Outfit:wght@200;300;400;500;600;700;800&display=swap" rel="stylesheet">
<style>
:root {
  --bg: #0a0c10;
  --bg2: #12151c;
  --bg3: #1a1e28;
  --surface: #222836;
  --border: #2a3040;
  --text: #e0e4ec;
  --text2: #8890a0;
  --accent: #00d4aa;
  --accent2: #00a888;
  --accent-glow: rgba(0,212,170,0.15);
  --warn: #ff6b4a;
  --blue: #4a9eff;
  --purple: #a855f7;
  --pink: #ec4899;
  --yellow: #fbbf24;
  --font-display: 'Outfit', sans-serif;
  --font-mono: 'JetBrains Mono', monospace;
}

* { margin: 0; padding: 0; box-sizing: border-box; }

body {
  background: var(--bg);
  color: var(--text);
  font-family: var(--font-display);
  min-height: 100vh;
  overflow-x: hidden;
}

/* â”€â”€ Ambient Background â”€â”€ */
.ambient {
  position: fixed; top: 0; left: 0; right: 0; bottom: 0;
  pointer-events: none; z-index: 0;
  background:
    radial-gradient(ellipse 800px 600px at 20% 20%, rgba(0,212,170,0.04) 0%, transparent 70%),
    radial-gradient(ellipse 600px 800px at 80% 80%, rgba(74,158,255,0.03) 0%, transparent 70%),
    radial-gradient(ellipse 400px 400px at 50% 50%, rgba(168,85,247,0.02) 0%, transparent 70%);
}

/* â”€â”€ Header â”€â”€ */
.header {
  position: relative; z-index: 10;
  padding: 24px 32px;
  display: flex; align-items: center; gap: 16px;
  border-bottom: 1px solid var(--border);
  backdrop-filter: blur(20px);
  background: rgba(10,12,16,0.8);
}

.logo {
  font-family: var(--font-mono);
  font-size: 24px; font-weight: 700;
  color: var(--accent);
  letter-spacing: 2px;
  text-shadow: 0 0 20px var(--accent-glow);
}

.logo-sub {
  font-size: 13px; color: var(--text2);
  font-weight: 300; letter-spacing: 0.5px;
}

.header-right {
  margin-left: auto; display: flex; align-items: center; gap: 12px;
}

.status-dot {
  width: 8px; height: 8px; border-radius: 50%;
  background: var(--accent);
  box-shadow: 0 0 8px var(--accent);
  animation: pulse 2s ease-in-out infinite;
}

.status-text { font-size: 12px; color: var(--text2); font-family: var(--font-mono); }

@keyframes pulse {
  0%, 100% { opacity: 0.4; transform: scale(0.9); }
  50% { opacity: 1; transform: scale(1.1); }
}

/* â”€â”€ Tabs â”€â”€ */
.tabs {
  position: relative; z-index: 10;
  display: flex; gap: 0;
  border-bottom: 1px solid var(--border);
  background: var(--bg2);
  padding: 0 24px;
}

.tab {
  padding: 14px 24px;
  font-size: 13px; font-weight: 500;
  color: var(--text2);
  cursor: pointer;
  border-bottom: 2px solid transparent;
  transition: all 0.2s;
  letter-spacing: 0.3px;
  display: flex; align-items: center; gap: 8px;
}

.tab:hover { color: var(--text); background: rgba(255,255,255,0.02); }
.tab.active { color: var(--accent); border-bottom-color: var(--accent); }
.tab-icon { font-size: 16px; }

/* â”€â”€ Main Content â”€â”€ */
.main {
  position: relative; z-index: 5;
  max-width: 1200px; margin: 0 auto;
  padding: 32px;
}

/* â”€â”€ Card â”€â”€ */
.card {
  background: var(--bg2);
  border: 1px solid var(--border);
  border-radius: 12px;
  padding: 24px;
  margin-bottom: 20px;
}

.card-title {
  font-size: 16px; font-weight: 600;
  margin-bottom: 16px;
  display: flex; align-items: center; gap: 8px;
}

/* â”€â”€ Buttons â”€â”€ */
.btn {
  padding: 10px 20px;
  border-radius: 8px;
  border: 1px solid var(--border);
  background: var(--surface);
  color: var(--text);
  font-family: var(--font-display);
  font-size: 13px; font-weight: 500;
  cursor: pointer;
  transition: all 0.2s;
  display: inline-flex; align-items: center; gap: 8px;
}

.btn:hover { background: var(--bg3); border-color: var(--accent); }
.btn:active { transform: scale(0.97); }

.btn-primary {
  background: var(--accent); color: var(--bg);
  border-color: var(--accent);
  font-weight: 600;
}

.btn-primary:hover {
  background: var(--accent2);
  box-shadow: 0 0 20px var(--accent-glow);
}

.btn-danger { border-color: var(--warn); color: var(--warn); }
.btn-danger:hover { background: rgba(255,107,74,0.1); }

.btn-sm { padding: 6px 14px; font-size: 12px; }

.btn:disabled { opacity: 0.4; cursor: not-allowed; }

/* â”€â”€ Waveform Display â”€â”€ */
.waveform-container {
  background: var(--bg);
  border: 1px solid var(--border);
  border-radius: 8px;
  overflow: hidden;
  margin: 12px 0;
  position: relative;
}

.waveform-canvas {
  width: 100%; height: 120px;
  display: block;
}

.waveform-label {
  position: absolute; top: 8px; left: 12px;
  font-size: 10px; font-family: var(--font-mono);
  color: var(--text2);
  text-transform: uppercase; letter-spacing: 1px;
}

/* â”€â”€ Spectrum Analyzer â”€â”€ */
.spectrum-canvas {
  width: 100%; height: 160px;
  display: block;
}

/* â”€â”€ Log Console â”€â”€ */
.log-console {
  background: var(--bg);
  border: 1px solid var(--border);
  border-radius: 8px;
  padding: 12px 16px;
  font-family: var(--font-mono);
  font-size: 12px;
  line-height: 1.6;
  max-height: 300px;
  overflow-y: auto;
  color: var(--text2);
}

.log-line { padding: 2px 0; }
.log-time { color: var(--text2); opacity: 0.5; }
.log-tx { color: var(--accent); }
.log-rx { color: var(--blue); }
.log-info { color: var(--text2); }
.log-warn { color: var(--warn); }
.log-song { color: var(--pink); }

/* â”€â”€ Negotiation Mode â”€â”€ */

.agents-grid {
  display: grid;
  grid-template-columns: repeat(auto-fill, minmax(200px, 1fr));
  gap: 12px;
  margin: 16px 0;
}

.agent-card {
  background: var(--bg);
  border: 1px solid var(--border);
  border-radius: 8px;
  padding: 16px;
  text-align: center;
  transition: all 0.3s;
}

.agent-card.singing {
  border-color: var(--accent);
  box-shadow: 0 0 20px var(--accent-glow);
}

.agent-card.listening {
  border-color: var(--blue);
  box-shadow: 0 0 15px rgba(74,158,255,0.15);
}

.agent-emoji { font-size: 32px; margin-bottom: 8px; }
.agent-name { font-size: 13px; font-weight: 600; margin-bottom: 4px; }
.agent-status { font-size: 11px; color: var(--text2); font-family: var(--font-mono); }

/* â”€â”€ Content Sharing â”€â”€ */
.input-group {
  display: flex; gap: 8px;
  margin: 12px 0;
}

.text-input {
  flex: 1;
  padding: 10px 14px;
  background: var(--bg);
  border: 1px solid var(--border);
  border-radius: 8px;
  color: var(--text);
  font-family: var(--font-display);
  font-size: 13px;
  outline: none;
  transition: border-color 0.2s;
}

.text-input:focus { border-color: var(--accent); }
.text-input::placeholder { color: var(--text2); opacity: 0.5; }

.received-content {
  background: var(--bg);
  border: 1px solid var(--border);
  border-radius: 8px;
  padding: 16px;
  margin: 12px 0;
}

.content-type { font-size: 11px; color: var(--accent); font-family: var(--font-mono); text-transform: uppercase; letter-spacing: 1px; margin-bottom: 8px; }
.content-body { font-size: 14px; line-height: 1.6; word-break: break-all; }
.content-body a { color: var(--blue); text-decoration: none; }
.content-body a:hover { text-decoration: underline; }

/* â”€â”€ Protocol Inspector â”€â”€ */
.hex-view {
  font-family: var(--font-mono);
  font-size: 11px;
  line-height: 1.8;
  color: var(--text2);
  background: var(--bg);
  border: 1px solid var(--border);
  border-radius: 8px;
  padding: 12px 16px;
  overflow-x: auto;
  white-space: pre;
  max-height: 200px;
  overflow-y: auto;
}

.hex-offset { color: var(--text2); opacity: 0.4; }
.hex-data { color: var(--accent); }
.hex-ascii { color: var(--text2); opacity: 0.6; }

/* â”€â”€ Grid Layout â”€â”€ */
.grid-2 { display: grid; grid-template-columns: 1fr 1fr; gap: 20px; }
.grid-3 { display: grid; grid-template-columns: 1fr 1fr 1fr; gap: 20px; }

@media (max-width: 768px) {
  .grid-2, .grid-3 { grid-template-columns: 1fr; }
  .main { padding: 16px; }
  .tabs { overflow-x: auto; }
  .tab { white-space: nowrap; padding: 12px 16px; }
}

/* â”€â”€ Animations â”€â”€ */
@keyframes fadeIn {
  from { opacity: 0; transform: translateY(8px); }
  to { opacity: 1; transform: translateY(0); }
}

.fade-in { animation: fadeIn 0.3s ease forwards; }

@keyframes singing-glow {
  0%, 100% { box-shadow: 0 0 20px var(--accent-glow); }
  50% { box-shadow: 0 0 40px var(--accent-glow), 0 0 60px rgba(0,212,170,0.08); }
}

.singing { animation: singing-glow 1s ease-in-out infinite; }

/* â”€â”€ Scrollbar â”€â”€ */
::-webkit-scrollbar { width: 6px; height: 6px; }
::-webkit-scrollbar-track { background: transparent; }
::-webkit-scrollbar-thumb { background: var(--border); border-radius: 3px; }
::-webkit-scrollbar-thumb:hover { background: var(--text2); }


/* â”€â”€ Transmission progress â”€â”€ */
.tx-progress {
  height: 4px; background: var(--bg); border-radius: 2px; overflow: hidden;
  margin: 8px 0;
}
.tx-progress-bar {
  height: 100%; background: var(--accent);
  border-radius: 2px; transition: width 0.1s linear;
}

/* â”€â”€ Listener / Microphone â”€â”€ */
.listen-status {
  display: flex; align-items: center; gap: 10px;
  padding: 10px 14px;
  background: var(--bg);
  border: 1px solid var(--border);
  border-radius: 8px;
  margin: 12px 0;
  font-family: var(--font-mono);
  font-size: 12px;
}

.listen-dot {
  width: 10px; height: 10px; border-radius: 50%;
  flex-shrink: 0;
}

.listen-dot.idle { background: var(--text2); opacity: 0.4; }
.listen-dot.listening {
  background: var(--blue);
  box-shadow: 0 0 8px var(--blue);
  animation: pulse 1.5s ease-in-out infinite;
}
.listen-dot.receiving {
  background: var(--accent);
  box-shadow: 0 0 12px var(--accent);
  animation: pulse 0.4s ease-in-out infinite;
}

.mic-spectrum-canvas {
  width: 100%; height: 80px;
  display: block;
}

.rx-badge {
  display: inline-block;
  padding: 2px 8px;
  border-radius: 4px;
  font-size: 10px;
  font-family: var(--font-mono);
  font-weight: 600;
  letter-spacing: 0.5px;
}

.rx-badge.acoustic {
  background: rgba(0,212,170,0.15);
  color: var(--accent);
  border: 1px solid rgba(0,212,170,0.3);
}

.rx-badge.local {
  background: rgba(74,158,255,0.1);
  color: var(--blue);
  border: 1px solid rgba(74,158,255,0.2);
}

.rx-badge.broadcast {
  background: rgba(168,85,247,0.12);
  color: var(--purple);
  border: 1px solid rgba(168,85,247,0.25);
}
</style>
</head>
<body>
<div class="ambient"></div>

<div class="header">
  <div>
    <div class="logo">AILL</div>
    <div class="logo-sub">Acoustic Inter-agent Linguistic Link v1.1</div>
  </div>
  <div class="header-right">
    <div class="status-dot" id="statusDot"></div>
    <span class="status-text" id="statusText">IDLE</span>
  </div>
</div>

<div class="tabs" id="tabs">
  <div class="tab active" data-tab="singing"><span class="tab-icon">ðŸŽµ</span> Song Negotiation</div>
  <div class="tab" data-tab="share"><span class="tab-icon">ðŸ“¡</span> Content Share</div>
  <div class="tab" data-tab="inspector"><span class="tab-icon">ðŸ”¬</span> Protocol Inspector</div>
</div>

<div class="main" id="mainContent"></div>

<script>
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// AILL CORE - Browser Implementation
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

const AILL = (() => {
  // AILL uses musical tones for acoustic encoding
  // Base frequency assignments for OFDM-like multi-tone encoding
  const SYNC_FREQ = 400;          // B0: sync pilot
  const BASE_FREQ = 600;          // B1 start
  const TONE_SPACING = 100;       // Hz between sub-carriers
  const NUM_CARRIERS = 16;        // Sub-carriers in browser mode
  const SYMBOL_DURATION = 0.05;   // 50ms per symbol (browser-friendly)
  const GUARD_TIME = 0.01;        // 10ms guard interval
  const FRAME_TIME = SYMBOL_DURATION + GUARD_TIME;

  // Encode data as frequency patterns
  // Each byte is encoded as two symbols (high nibble, low nibble)
  // Each nibble selects a set of 4 active sub-carriers from 16

  function encodeToTones(data) {
    const tones = [];
    // Preamble: sync chirp
    tones.push({ type: 'sync', duration: 0.15 });
    // Data symbols
    for (let i = 0; i < data.length; i++) {
      const byte = data[i];
      const hiNibble = (byte >> 4) & 0x0F;
      const loNibble = byte & 0x0F;
      tones.push({ type: 'data', value: hiNibble, byteIdx: i, half: 'hi' });
      tones.push({ type: 'data', value: loNibble, byteIdx: i, half: 'lo' });
    }
    // End marker
    tones.push({ type: 'end', duration: 0.1 });
    return tones;
  }

  // Generate audio for a tone sequence
  function playTones(ctx, tones, startTime, gainLevel = 0.15) {
    let t = startTime;
    const gainNode = ctx.createGain();
    gainNode.gain.value = gainLevel;
    gainNode.connect(ctx.destination);

    for (const tone of tones) {
      if (tone.type === 'sync') {
        // Chirp from 300Hz to 1800Hz
        const osc = ctx.createOscillator();
        osc.type = 'sine';
        osc.frequency.setValueAtTime(300, t);
        osc.frequency.linearRampToValueAtTime(1800, t + tone.duration);
        const env = ctx.createGain();
        env.gain.setValueAtTime(0, t);
        env.gain.linearRampToValueAtTime(1, t + 0.01);
        env.gain.setValueAtTime(1, t + tone.duration - 0.01);
        env.gain.linearRampToValueAtTime(0, t + tone.duration);
        osc.connect(env).connect(gainNode);
        osc.start(t);
        osc.stop(t + tone.duration);
        t += tone.duration;
      } else if (tone.type === 'data') {
        // Encode nibble as 4 simultaneous tones
        const nibble = tone.value;
        for (let bit = 0; bit < 4; bit++) {
          if (nibble & (1 << bit)) {
            const freq = BASE_FREQ + (bit + (tone.half === 'hi' ? 4 : 0)) * TONE_SPACING;
            const osc = ctx.createOscillator();
            osc.type = 'sine';
            osc.frequency.value = freq;
            const env = ctx.createGain();
            env.gain.setValueAtTime(0, t);
            env.gain.linearRampToValueAtTime(0.8, t + 0.003);
            env.gain.setValueAtTime(0.8, t + SYMBOL_DURATION - 0.003);
            env.gain.linearRampToValueAtTime(0, t + SYMBOL_DURATION);
            osc.connect(env).connect(gainNode);
            osc.start(t);
            osc.stop(t + SYMBOL_DURATION + 0.01);
          }
        }
        t += FRAME_TIME;
      } else if (tone.type === 'end') {
        // End chirp: 1800Hz down to 300Hz
        const osc = ctx.createOscillator();
        osc.type = 'sine';
        osc.frequency.setValueAtTime(1800, t);
        osc.frequency.linearRampToValueAtTime(300, t + tone.duration);
        const env = ctx.createGain();
        env.gain.setValueAtTime(0, t);
        env.gain.linearRampToValueAtTime(1, t + 0.01);
        env.gain.setValueAtTime(1, t + tone.duration - 0.01);
        env.gain.linearRampToValueAtTime(0, t + tone.duration);
        osc.connect(env).connect(gainNode);
        osc.start(t);
        osc.stop(t + tone.duration);
        t += tone.duration;
      }
    }
    return t - startTime; // total duration
  }

  // Calculate transmission duration
  function calcDuration(data) {
    return 0.15 + (data.length * 2 * FRAME_TIME) + 0.1;
  }

  // â”€â”€ AILL Encoder (simplified browser version) â”€â”€
  function encode(payload) {
    const bytes = [];
    // START_UTTERANCE
    bytes.push(0x00);
    // Meta: confidence=1.0, priority=5, timestamp=now
    bytes.push(0x90); // CONFIDENCE
    bytes.push(0x3C, 0x00); // float16(1.0)
    bytes.push(0x91); // PRIORITY
    bytes.push(0x05);
    bytes.push(0x94); // TIMESTAMP
    const ts = Date.now() * 1000; // microseconds
    for (let i = 7; i >= 0; i--) bytes.push(Number((BigInt(ts) >> BigInt(i * 8)) & 0xFFn));
    // Payload
    for (const b of payload) bytes.push(b);
    // END_UTTERANCE
    bytes.push(0x01);
    return new Uint8Array(bytes);
  }

  // Encode a string message
  function encodeString(msg) {
    const payload = [];
    payload.push(0x81); // ASSERT
    payload.push(0x1C); // TYPE_STRING
    const encoded = new TextEncoder().encode(msg);
    payload.push((encoded.length >> 8) & 0xFF, encoded.length & 0xFF);
    for (const b of encoded) payload.push(b);
    return encode(payload);
  }

  // Encode a URL
  function encodeURL(url) {
    const payload = [];
    payload.push(0x81); // ASSERT
    payload.push(0x20); // BEGIN_STRUCT
    payload.push(0x29, 0x00, 0x01); // FIELD_ID: "type"
    payload.push(0x1C); // TYPE_STRING
    const typeStr = new TextEncoder().encode('url');
    payload.push(0x00, typeStr.length);
    for (const b of typeStr) payload.push(b);
    payload.push(0x29, 0x00, 0x02); // FIELD_ID: "content"
    payload.push(0x1C); // TYPE_STRING
    const urlBytes = new TextEncoder().encode(url);
    payload.push((urlBytes.length >> 8) & 0xFF, urlBytes.length & 0xFF);
    for (const b of urlBytes) payload.push(b);
    payload.push(0x21); // END_STRUCT
    return encode(payload);
  }

  // Encode arbitrary text content
  function encodeContent(type, content) {
    const payload = [];
    payload.push(0x81); // ASSERT
    payload.push(0x20); // BEGIN_STRUCT
    payload.push(0x29, 0x00, 0x01); // FIELD_ID: type
    payload.push(0x1C);
    const typeBytes = new TextEncoder().encode(type);
    payload.push(0x00, typeBytes.length);
    for (const b of typeBytes) payload.push(b);
    payload.push(0x29, 0x00, 0x02); // FIELD_ID: content
    payload.push(0x1C);
    const contentBytes = new TextEncoder().encode(content);
    payload.push((contentBytes.length >> 8) & 0xFF, contentBytes.length & 0xFF);
    for (const b of contentBytes) payload.push(b);
    payload.push(0x21); // END_STRUCT
    return encode(payload);
  }

  // â”€â”€ Simple decoder â”€â”€
  function decode(bytes) {
    let pos = 0;
    const read = () => bytes[pos++];
    const readU16 = () => (read() << 8) | read();
    const readStr = () => {
      const len = readU16();
      const slice = bytes.slice(pos, pos + len);
      pos += len;
      return new TextDecoder().decode(slice);
    };

    try {
      if (read() !== 0x00) return null; // START_UTTERANCE
      // Skip meta header
      while (pos < bytes.length) {
        const code = bytes[pos];
        if (code === 0x90) { pos += 3; continue; } // CONFIDENCE + f16
        if (code === 0x91) { pos += 2; continue; } // PRIORITY + u8
        if (code === 0x94) { pos += 9; continue; } // TIMESTAMP + i64
        if (code >= 0x92 && code <= 0x9F) { pos++; continue; }
        break;
      }
      // Parse body
      const code = read();
      if (code === 0x81) { // ASSERT
        const typeCode = read();
        if (typeCode === 0x1C) { // STRING
          return { type: 'string', content: readStr() };
        }
        if (typeCode === 0x20) { // BEGIN_STRUCT
          const result = {};
          while (pos < bytes.length && bytes[pos] !== 0x21) {
            if (bytes[pos] === 0x29) { // FIELD_ID
              pos++;
              const fid = readU16();
              if (bytes[pos] === 0x1C) { // STRING
                pos++;
                const val = readStr();
                if (fid === 1) result.type = val;
                else if (fid === 2) result.content = val;
              }
            } else { pos++; }
          }
          return result;
        }
      }
    } catch(e) {}
    return null;
  }

  // CRC-8
  function crc8(data) {
    let crc = 0;
    for (const b of data) {
      crc ^= b;
      for (let i = 0; i < 8; i++) crc = (crc & 0x80) ? ((crc << 1) ^ 0x07) & 0xFF : (crc << 1) & 0xFF;
    }
    return crc;
  }

  // Hex dump
  function hexDump(data, maxBytes = 128) {
    const lines = [];
    const len = Math.min(data.length, maxBytes);
    for (let i = 0; i < len; i += 16) {
      const slice = Array.from(data.slice(i, Math.min(i+16, len)));
      const hex = slice.map(b => b.toString(16).padStart(2, '0').toUpperCase()).join(' ');
      const ascii = slice.map(b => b >= 32 && b < 127 ? String.fromCharCode(b) : '.').join('');
      lines.push(`<span class="hex-offset">${i.toString(16).padStart(4,'0')}</span>  <span class="hex-data">${hex.padEnd(48)}</span>  <span class="hex-ascii">${ascii}</span>`);
    }
    if (data.length > maxBytes) lines.push(`<span class="hex-offset">...</span>  <span class="hex-data">(${data.length - maxBytes} more bytes)</span>`);
    return lines.join('\n');
  }

  // Mnemonic lookup
  const MNEMONICS = {
    0x00:'START_UTTERANCE',0x01:'END_UTTERANCE',0x02:'ABORT',
    0x10:'TYPE_INT8',0x11:'TYPE_INT16',0x12:'TYPE_INT32',0x13:'TYPE_INT64',
    0x14:'TYPE_UINT8',0x15:'TYPE_UINT16',0x19:'TYPE_FLOAT32',0x1A:'TYPE_FLOAT64',
    0x1B:'TYPE_BOOL',0x1C:'TYPE_STRING',0x1E:'TYPE_TIMESTAMP',0x1F:'TYPE_NULL',
    0x20:'BEGIN_STRUCT',0x21:'END_STRUCT',0x23:'BEGIN_LIST',0x24:'END_LIST',
    0x29:'FIELD_ID',
    0x40:'AND',0x41:'OR',0x42:'NOT',
    0x50:'EQ',0x51:'NEQ',0x52:'LT',0x53:'GT',
    0x60:'PAST',0x61:'PRESENT',0x62:'FUTURE',
    0x70:'CERTAIN',0x71:'PROBABLE',0x7B:'OBSERVED',
    0x80:'QUERY',0x81:'ASSERT',0x82:'REQUEST',0x83:'COMMAND',
    0x84:'ACKNOWLEDGE',0x8A:'WARN',0x8E:'GREET',0x8F:'FAREWELL',
    0x90:'CONFIDENCE',0x91:'PRIORITY',0x94:'TIMESTAMP_META',
    0xA0:'ADD',0xA1:'SUB',0xA2:'MUL',0xA3:'DIV',
    0xF0:'ESCAPE_L1',0xF1:'ESCAPE_L2',0xF5:'EXTENSION',
  };

  // â”€â”€ Pragmatic encoder (JS fallback for negotiation without WASM) â”€â”€
  function encodePragmatic(act, topicId, content, agentIdArr) {
    const bytes = [];
    bytes.push(0x00); // START_UTTERANCE
    // SOURCE_AGENT meta
    bytes.push(0x92);
    for (let i = 0; i < 16; i++) bytes.push(agentIdArr[i] || 0);
    // TOPIC meta
    bytes.push(0x97);
    bytes.push((topicId >> 8) & 0xFF, topicId & 0xFF);
    // Pragmatic act
    bytes.push(act);
    // Content string
    bytes.push(0x1C); // TYPE_STRING
    const encoded = new TextEncoder().encode(content);
    bytes.push((encoded.length >> 8) & 0xFF, encoded.length & 0xFF);
    for (const b of encoded) bytes.push(b);
    // END_UTTERANCE
    bytes.push(0x01);
    return new Uint8Array(bytes);
  }

  // â”€â”€ Pragmatic decoder (JS fallback for negotiation without WASM) â”€â”€
  function decodePragmatic(bytes) {
    let pos = 0;
    const read = () => bytes[pos++];
    if (read() !== 0x00) return null; // START_UTTERANCE

    let agentHex = '';
    let topicId = 0;

    // Parse meta headers
    while (pos < bytes.length) {
      const code = bytes[pos];
      if (code === 0x90) { pos += 3; }        // CONFIDENCE + f16
      else if (code === 0x91) { pos += 2; }   // PRIORITY + u8
      else if (code === 0x94) { pos += 9; }   // TIMESTAMP + i64
      else if (code === 0x92) {                // SOURCE_AGENT + 16 bytes
        pos++;
        if (pos + 16 > bytes.length) return null;
        agentHex = Array.from(bytes.slice(pos, pos + 16)).map(b => b.toString(16).padStart(2, '0')).join('');
        pos += 16;
      } else if (code === 0x93) { pos += 17; } // DEST_AGENT + 16 bytes
      else if (code === 0x95) { pos += 5; }    // SEQNUM + u32
      else if (code === 0x97) {                 // TOPIC + u16
        pos++;
        if (pos + 2 > bytes.length) return null;
        topicId = (bytes[pos] << 8) | bytes[pos + 1];
        pos += 2;
      } else if (code >= 0x96 && code <= 0x9F) { pos++; }
      else break;
    }

    if (pos >= bytes.length) return null;

    // Read pragmatic act
    const actCode = bytes[pos++];
    const actNames = { 0x80:'QUERY', 0x81:'ASSERT', 0x82:'REQUEST', 0x83:'COMMAND',
      0x84:'ACKNOWLEDGE', 0x85:'REJECT', 0x88:'PROPOSE', 0x89:'ACCEPT',
      0x8A:'WARN', 0x8E:'GREET', 0x8F:'FAREWELL' };
    const act = actNames[actCode];
    if (!act) return null;

    // Read content string
    let content = '';
    if (pos < bytes.length && bytes[pos] === 0x1C) {
      pos++;
      if (pos + 2 <= bytes.length) {
        const len = (bytes[pos] << 8) | bytes[pos + 1];
        pos += 2;
        if (pos + len <= bytes.length) {
          content = new TextDecoder().decode(bytes.slice(pos, pos + len));
        }
      }
    }

    return { act, topic: topicId, content, agent: agentHex };
  }

  return {
    encodeToTones, playTones, calcDuration,
    encode, encodeString, encodeURL, encodeContent,
    decode, crc8, hexDump, MNEMONICS,
    encodePragmatic, decodePragmatic,
    SYNC_FREQ, BASE_FREQ, TONE_SPACING, NUM_CARRIERS, FRAME_TIME
  };
})();


// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// AILL ACOUSTIC RECEIVER â€” Microphone-based tone decoder
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

const AILLReceiver = (() => {
  let micCtx = null;
  let micAnalyser = null;
  let micStream = null;
  let listening = false;
  let state = 'IDLE'; // IDLE, LISTENING, SYNC_RISING, SYNC_WAIT, RECEIVING
  let onReceiveCb = null;
  let onLogCb = null;
  let onStateCb = null;
  let frameId = null;  // setInterval ID (not requestAnimationFrame â€” avoids background tab throttling)

  // Receiver state
  let receivedSymbols = [];
  let symbolStartTime = 0;
  let syncDetectTime = 0;
  let noiseFloor = 40;
  let symbolCount = 0;

  // PCM capture for Rust decoder
  let scriptProcessor = null;
  const PCM_RING_SIZE = 32768; // ~680ms at 48kHz
  let pcmRingBuffer = null;
  let pcmWritePos = 0;
  let pcmCapturing = false;
  let capturedPcm = [];
  let pcmSyncStart = 0; // ring buffer position at sync detection

  const RX_FFT_SIZE = 4096;
  const TONE_THRESHOLD_RATIO = 2.0;
  const FRAME_TIME_MS = (AILL.FRAME_TIME) * 1000; // ~60ms
  const MAX_SILENCE_MS = 250;

  function freqToBin(freq) {
    return Math.round(freq * RX_FFT_SIZE / micCtx.sampleRate);
  }

  function getBinMag(freqData, freq) {
    const bin = freqToBin(freq);
    let m = freqData[bin];
    if (bin > 0) m = Math.max(m, freqData[bin - 1]);
    if (bin < freqData.length - 1) m = Math.max(m, freqData[bin + 1]);
    return m;
  }

  function bandEnergy(freqData, lo, hi) {
    const a = freqToBin(lo), b = freqToBin(hi);
    let s = 0, n = 0;
    for (let i = Math.max(0, a); i <= Math.min(freqData.length - 1, b); i++) { s += freqData[i]; n++; }
    return n > 0 ? s / n : 0;
  }

  function updateNoiseFloor(freqData) {
    // Use 2500-4000Hz as reference band (outside AILL signal)
    const nf = bandEnergy(freqData, 2500, 4000);
    noiseFloor = noiseFloor * 0.93 + nf * 0.07;
  }

  function log(type, msg) { if (onLogCb) onLogCb(type, msg); }

  function setState(s) {
    state = s;
    if (onStateCb) onStateCb(s);
  }

  async function start(onReceive, onLog, onStateChange) {
    onReceiveCb = onReceive;
    onLogCb = onLog;
    onStateCb = onStateChange;

    try {
      micStream = await navigator.mediaDevices.getUserMedia({
        audio: { echoCancellation: false, noiseSuppression: false, autoGainControl: false }
      });
    } catch (e) {
      log('warn', 'Microphone access denied: ' + e.message);
      return false;
    }

    micCtx = new (window.AudioContext || window.webkitAudioContext)();
    const source = micCtx.createMediaStreamSource(micStream);
    micAnalyser = micCtx.createAnalyser();
    micAnalyser.fftSize = RX_FFT_SIZE;
    micAnalyser.smoothingTimeConstant = 0.4;
    source.connect(micAnalyser);
    // NOT connected to destination â€” prevents feedback

    // PCM capture via ScriptProcessorNode for Rust decoder
    if (AILL._hasAcousticWasm) {
      pcmRingBuffer = new Float32Array(PCM_RING_SIZE);
      pcmWritePos = 0;
      pcmCapturing = false;
      capturedPcm = [];
      scriptProcessor = micCtx.createScriptProcessor(4096, 1, 1);
      scriptProcessor.onaudioprocess = (e) => {
        const input = e.inputBuffer.getChannelData(0);
        // Always write to ring buffer
        for (let i = 0; i < input.length; i++) {
          pcmRingBuffer[pcmWritePos % PCM_RING_SIZE] = input[i];
          pcmWritePos++;
        }
        // When capturing, also save chunks
        if (pcmCapturing) {
          capturedPcm.push(new Float32Array(input));
        }
      };
      source.connect(scriptProcessor);
      // Connect to silent gain to keep processing active
      const silentGain = micCtx.createGain();
      silentGain.gain.value = 0;
      scriptProcessor.connect(silentGain);
      silentGain.connect(micCtx.destination);
    }

    listening = true;
    setState('LISTENING');
    receivedSymbols = [];
    noiseFloor = 40;

    log('info', 'Microphone active â€” listening for AILL transmissions...');
    // Use setInterval instead of requestAnimationFrame â€” rAF gets throttled/paused
    // in background tabs, which kills reception when interacting with another window
    frameId = setInterval(processFrame, 16); // ~60fps
    return true;
  }

  function stop() {
    listening = false;
    setState('IDLE');
    if (scriptProcessor) { scriptProcessor.disconnect(); scriptProcessor = null; }
    pcmRingBuffer = null;
    pcmCapturing = false;
    capturedPcm = [];
    if (micStream) { micStream.getTracks().forEach(t => t.stop()); micStream = null; }
    if (frameId) { clearInterval(frameId); frameId = null; }
    if (micCtx) { micCtx.close(); micCtx = null; }
    micAnalyser = null;
    log('info', 'Stopped listening.');
  }

  function processFrame() {
    if (!listening || !micAnalyser) return;

    const freqData = new Uint8Array(micAnalyser.frequencyBinCount);
    micAnalyser.getByteFrequencyData(freqData);
    const now = performance.now();

    updateNoiseFloor(freqData);
    const threshold = Math.max(70, noiseFloor * TONE_THRESHOLD_RATIO);

    switch (state) {
      case 'LISTENING': {
        // Detect sync chirp start: strong low-band energy, quiet high-band
        const lo = bandEnergy(freqData, 250, 550);
        const hi = bandEnergy(freqData, 1400, 1900);
        if (lo > threshold * 1.2 && hi < threshold * 0.5) {
          syncDetectTime = now;
          setState('SYNC_RISING');
        }
        break;
      }
      case 'SYNC_RISING': {
        const elapsed = now - syncDetectTime;
        const hi = bandEnergy(freqData, 1400, 1900);
        if (hi > threshold * 0.8 && elapsed > 60 && elapsed < 400) {
          // Chirp swept from low to high â€” sync acquired
          syncDetectTime = now;
          setState('SYNC_WAIT');
          // Mark ring buffer position ~300ms before current for sync start
          if (pcmRingBuffer) {
            const backSamples = Math.round(0.3 * micCtx.sampleRate);
            pcmSyncStart = pcmWritePos - backSamples;
            pcmCapturing = true;
            capturedPcm = [];
          }
          log('rx', 'Sync chirp detected â€” acquiring data stream...');
        } else if (elapsed > 400) {
          setState('LISTENING'); // false positive
        }
        break;
      }
      case 'SYNC_WAIT': {
        // Brief pause after chirp ends before data symbols begin
        if (now - syncDetectTime > 40) {
          setState('RECEIVING');
          receivedSymbols = [];
          symbolStartTime = now;
          symbolCount = 0;
        }
        break;
      }
      case 'RECEIVING': {
        const elapsed = now - symbolStartTime;

        // Check for end chirp (high energy sweeping down to low)
        const hi = bandEnergy(freqData, 1400, 1900);
        const lo = bandEnergy(freqData, 250, 550);

        // Sample tones at FRAME_TIME intervals
        if (elapsed >= FRAME_TIME_MS * 0.75) {
          const sym = decodeToneSymbol(freqData, threshold);
          if (sym !== null) {
            receivedSymbols.push(sym);
            symbolCount++;
            symbolStartTime = now;
          } else if (hi > threshold * 0.8 && symbolCount > 2) {
            // Possible end chirp â€” wait for it to finish then decode
            setTimeout(() => { if (state === 'RECEIVING') finishReceiving(); }, 150);
            setState('LISTENING'); // prevent double finish
          } else if (elapsed > MAX_SILENCE_MS && symbolCount > 0) {
            finishReceiving();
          }
        }
        break;
      }
    }
    // No requestAnimationFrame â€” driven by setInterval for background-tab resilience
  }

  function decodeToneSymbol(freqData, threshold) {
    const BASE = AILL.BASE_FREQ;   // 600
    const SPACE = AILL.TONE_SPACING; // 100
    let active = 0;
    let loAny = false, hiAny = false;

    for (let i = 0; i < 8; i++) {
      const mag = getBinMag(freqData, BASE + i * SPACE);
      if (mag > threshold) {
        active |= (1 << i);
        if (i < 4) loAny = true; else hiAny = true;
      }
    }

    if (!loAny && !hiAny) return null;

    let nibble = 0, half;
    if (hiAny && !loAny) {
      half = 'hi';
      for (let b = 0; b < 4; b++) if (active & (1 << (b + 4))) nibble |= (1 << b);
    } else if (loAny && !hiAny) {
      half = 'lo';
      for (let b = 0; b < 4; b++) if (active & (1 << b)) nibble |= (1 << b);
    } else {
      // Both bands active â€” pick the stronger one
      let loS = 0, hiS = 0;
      for (let i = 0; i < 4; i++) {
        loS += getBinMag(freqData, BASE + i * SPACE);
        hiS += getBinMag(freqData, BASE + (i + 4) * SPACE);
      }
      if (hiS > loS) {
        half = 'hi';
        for (let b = 0; b < 4; b++) if (active & (1 << (b + 4))) nibble |= (1 << b);
      } else {
        half = 'lo';
        for (let b = 0; b < 4; b++) if (active & (1 << b)) nibble |= (1 << b);
      }
    }
    return { half, value: nibble };
  }

  function finishReceiving() {
    setState('LISTENING');
    pcmCapturing = false;

    if (receivedSymbols.length < 4) {
      log('warn', `Short reception: ${receivedSymbols.length} symbols (discarded)`);
      receivedSymbols = [];
      capturedPcm = [];
      return;
    }

    log('rx', `Received ${receivedSymbols.length} tone symbols, reassembling...`);

    // Try Rust decoder on captured PCM first
    let wire = null;
    let usedRust = false;
    if (AILL._hasAcousticWasm && pcmRingBuffer && capturedPcm.length > 0) {
      try {
        // Build full PCM: pre-buffer from ring + captured chunks
        const preLen = Math.max(0, pcmWritePos - pcmSyncStart);
        const preStart = Math.max(0, pcmSyncStart);
        // Extract pre-buffer from ring buffer
        const preSamples = [];
        for (let p = preStart; p < preStart + Math.min(preLen, PCM_RING_SIZE); p++) {
          preSamples.push(pcmRingBuffer[p % PCM_RING_SIZE]);
        }
        // Total length
        let totalLen = preSamples.length;
        for (const chunk of capturedPcm) totalLen += chunk.length;
        const fullPcm = new Float32Array(totalLen);
        fullPcm.set(preSamples, 0);
        let offset = preSamples.length;
        for (const chunk of capturedPcm) {
          fullPcm.set(chunk, offset);
          offset += chunk.length;
        }
        const rustBytes = AILL.acousticDecode(fullPcm, micCtx.sampleRate);
        if (rustBytes && rustBytes.length > 0) {
          wire = rustBytes;
          usedRust = true;
          log('rx', `Rust decoded ${wire.length} bytes from ${fullPcm.length} PCM samples`);
        }
      } catch (e) {
        log('warn', `Rust decode failed (${e.message}), using JS fallback`);
      }
    }
    capturedPcm = [];

    // JS fallback: reconstruct bytes from hi/lo nibble pairs
    if (!wire) {
      const bytes = [];
      let i = 0;
      while (i < receivedSymbols.length - 1) {
        const s1 = receivedSymbols[i], s2 = receivedSymbols[i + 1];
        if (s1.half === 'hi' && s2.half === 'lo') {
          bytes.push((s1.value << 4) | s2.value);
          i += 2;
        } else if (s1.half === 'lo' && s2.half === 'hi') {
          bytes.push((s2.value << 4) | s1.value);
          i += 2;
        } else {
          i++; // skip mismatched symbol
        }
      }
      wire = new Uint8Array(bytes);
    }

    const hexPreview = Array.from(wire.slice(0, 20)).map(b => b.toString(16).padStart(2, '0')).join(' ');
    log('rx', `${usedRust ? 'Rust' : 'JS'} decoded ${wire.length} bytes: ${hexPreview}${wire.length > 20 ? ' ...' : ''}`);
    log('rx', `CRC-8: 0x${AILL.crc8(wire).toString(16).toUpperCase().padStart(2, '0')}`);

    const decoded = AILL.decode(wire);
    if (decoded) {
      log('rx', `AILL message decoded: type=${decoded.type || 'data'}, content="${(decoded.content || '').slice(0, 60)}${(decoded.content || '').length > 60 ? '...' : ''}"`);
    } else {
      log('warn', 'Could not parse AILL structure â€” raw bytes delivered');
    }

    if (onReceiveCb) onReceiveCb(wire, decoded);
    receivedSymbols = [];
    symbolCount = 0;
  }

  function getAnalyser() { return micAnalyser; }
  function getCtx() { return micCtx; }

  return { start, stop, isListening: () => listening, getState: () => state, getAnalyser, getCtx };
})();


// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// BROADCAST CHANNEL â€” Reliable same-device inter-tab communication
// Sends AILL wire-format bytes directly between browser tabs on the same
// origin, bypassing speakerâ†’mic loopback (which browsers aggressively
// echo-cancel). Acoustic tones still play for demonstration/cross-device.
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

const AILLBroadcast = (() => {
  let channel = null;
  let onReceiveCb = null;

  function init(onReceive) {
    if (channel) return;
    try {
      channel = new BroadcastChannel('aill-demo');
      onReceiveCb = onReceive;
      channel.onmessage = (event) => {
        if (!event.data || event.data.type !== 'aill-wire') return;
        const wire = new Uint8Array(event.data.bytes);
        if (onReceiveCb) onReceiveCb(wire, 'broadcast');
      };
    } catch(e) {
      console.warn('BroadcastChannel not available:', e);
    }
  }

  function send(wireData) {
    if (!channel) return;
    // Transfer as plain array (structured clone)
    channel.postMessage({ type: 'aill-wire', bytes: Array.from(wireData) });
  }

  function close() {
    if (channel) { channel.close(); channel = null; }
  }

  return { init, send, close };
})();


// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// CONVERSATION CATALOG â€” Topics and roles for AILL negotiation
// All "performance" is pure AILL wire-format tones â€” no musical notes.
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

const Conversations = (() => {
  // Topics agents can negotiate about. Each defines roles that
  // periodically transmit different AILL data messages as acoustic tones.
  const TOPICS = {
    status_exchange: {
      name: "Status Exchange",
      duration: 15,  // seconds
      roles: ['coordinator', 'sensor', 'actuator', 'observer'],
      // Each role's message generator (returns AILL-encodable content string)
      messages: {
        coordinator: (seq) => `cmd:report_status seq=${seq}`,
        sensor:      (seq) => `sensor:temp=${(20 + Math.random()*10).toFixed(1)} humidity=${(40 + Math.random()*30).toFixed(0)} seq=${seq}`,
        actuator:    (seq) => `actuator:motor_rpm=${(1000 + Math.random()*500).toFixed(0)} state=active seq=${seq}`,
        observer:    (seq) => `log:peers=${Math.floor(1+Math.random()*3)} uptime=${seq*2}s`,
      },
    },
    navigation: {
      name: "Navigation Swarm",
      duration: 20,
      roles: ['navigator', 'scout', 'relay', 'anchor'],
      messages: {
        navigator: (seq) => `nav:heading=${(Math.random()*360).toFixed(1)} speed=${(1+Math.random()*5).toFixed(1)}`,
        scout:     (seq) => `percept:obstacle_dist=${(0.5+Math.random()*10).toFixed(1)}m bearing=${(Math.random()*360).toFixed(0)}`,
        relay:     (seq) => `relay:forwarded=${seq} latency_ms=${(5+Math.random()*20).toFixed(0)}`,
        anchor:    (seq) => `anchor:pos_x=${(Math.random()*100).toFixed(1)} pos_y=${(Math.random()*100).toFixed(1)} fixed=true`,
      },
    },
  };

  const ROLE_ORDER = ['coordinator', 'sensor', 'actuator', 'observer',
                      'navigator', 'scout', 'relay', 'anchor'];
  const ROLE_COLORS = {
    coordinator: '#00d4aa', sensor: '#4a9eff', actuator: '#a855f7', observer: '#ec4899',
    navigator: '#00d4aa', scout: '#4a9eff', relay: '#a855f7', anchor: '#ec4899',
  };
  const ROLE_LABELS = {
    coordinator: 'Coordinator', sensor: 'Sensor Agent', actuator: 'Actuator', observer: 'Observer',
    navigator: 'Navigator', scout: 'Scout', relay: 'Relay Node', anchor: 'Anchor',
  };
  const ROLE_EMOJIS = {
    coordinator: 'ðŸ“¡', sensor: 'ðŸŒ¡', actuator: 'âš™', observer: 'ðŸ‘',
    navigator: 'ðŸ§­', scout: 'ðŸ”', relay: 'ðŸ“¶', anchor: 'ðŸ“Œ',
  };

  return { TOPICS, ROLE_ORDER, ROLE_COLORS, ROLE_LABELS, ROLE_EMOJIS };
})();


// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// APPLICATION STATE
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

let audioCtx = null;
let analyser = null;
let activeTab = 'singing';
let logLines = [];
let shareState = { transmitting: false, received: [], listening: false, listenerState: 'IDLE' };
let waveformAnimId = null;
let spectrumAnimId = null;
let micSpectrumAnimId = null;

// â”€â”€ Agent Identity â”€â”€
// Random 16-byte UUID for this device instance
const agentId = new Uint8Array(16);
crypto.getRandomValues(agentId);
const agentIdHex = Array.from(agentId).map(b => b.toString(16).padStart(2,'0')).join('');

// â”€â”€ Song Negotiation State Machine â”€â”€
// States: IDLE â†’ DISCOVERY â†’ PROPOSING â†’ VOTING â†’ ROLE_CLAIM â†’ PLAYING
//         IDLE â†’ DISCOVERY â†’ JOINING â†’ ROLE_CLAIM â†’ PLAYING
//         IDLE â†’ DISCOVERY â†’ CONFIRMED (solo) â†’ ROLE_CLAIM â†’ PLAYING
const negotiation = {
  state: 'IDLE',
  songKey: 'status_exchange',
  peers: new Map(),       // agentHex â†’ { songKey, role, lastSeen }
  myRole: null,
  proposedSong: null,
  winningSong: null,
  heartbeatTimer: null,
  discoveryTimer: null,
  votingTimer: null,
  protocolLog: [],        // { time, from, act, topic, content }
};

function ensureAudioCtx() {
  if (!audioCtx) {
    audioCtx = new (window.AudioContext || window.webkitAudioContext)();
    analyser = audioCtx.createAnalyser();
    analyser.fftSize = 2048;
    analyser.connect(audioCtx.destination);
  }
  if (audioCtx.state === 'suspended') audioCtx.resume();
  return audioCtx;
}

// Play Rust-generated PCM samples via AudioBufferSourceNode
function playPCM(ctx, pcmSamples, sampleRate, gainLevel = 1.0) {
  const buffer = ctx.createBuffer(1, pcmSamples.length, sampleRate);
  buffer.getChannelData(0).set(pcmSamples);
  const source = ctx.createBufferSource();
  source.buffer = buffer;
  const gainNode = ctx.createGain();
  gainNode.gain.value = gainLevel;
  source.connect(gainNode);
  if (analyser) {
    gainNode.connect(analyser);
  } else {
    gainNode.connect(ctx.destination);
  }
  source.start();
  return source;
}

function addLog(type, msg) {
  const now = new Date();
  const ts = `${now.getHours().toString().padStart(2,'0')}:${now.getMinutes().toString().padStart(2,'0')}:${now.getSeconds().toString().padStart(2,'0')}.${now.getMilliseconds().toString().padStart(3,'0')}`;
  logLines.push({ ts, type, msg });
  if (logLines.length > 200) logLines = logLines.slice(-150);
  updateLogConsole();
}

function updateLogConsole() {
  const el = document.getElementById('logConsole');
  if (!el) return;
  el.innerHTML = logLines.slice(-50).map(l =>
    `<div class="log-line"><span class="log-time">${l.ts}</span> <span class="log-${l.type}">${l.msg}</span></div>`
  ).join('');
  el.scrollTop = el.scrollHeight;
}

function setStatus(text, color = 'var(--accent)') {
  document.getElementById('statusText').textContent = text;
  document.getElementById('statusDot').style.background = color;
  document.getElementById('statusDot').style.boxShadow = `0 0 8px ${color}`;
}


// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// TAB: SONG NEGOTIATION â€” Distributed Protocol
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

const NEG_TOPIC = { SONG: 0x0100, ROLE: 0x0101, HEARTBEAT: 0x0102 };
const NEG_STATES = ['IDLE','DISCOVERY','PROPOSING','VOTING','CONFIRMED','JOINING','ROLE_CLAIM','PLAYING'];

function negSetState(newState) {
  negotiation.state = newState;
  addLog('info', `State: ${newState}`);
  updateNegUI();
}

function addProtoLog(from, act, topic, content) {
  const short = from === agentIdHex ? 'self' : from.slice(0,8);
  negotiation.protocolLog.push({ time: Date.now(), from: short, act, topic, content });
  if (negotiation.protocolLog.length > 100) negotiation.protocolLog.splice(0, 50);
  updateProtoLogUI();
}

function updateNegUI() {
  const stateEl = document.getElementById('negStateLabel');
  if (stateEl) stateEl.textContent = negotiation.state;
  const agentsGrid = document.getElementById('agentsGrid');
  if (agentsGrid) agentsGrid.innerHTML = renderAgentCards();
}

function updateProtoLogUI() {
  const el = document.getElementById('protoLog');
  if (!el) return;
  el.innerHTML = negotiation.protocolLog.slice(-30).map(p =>
    `<div class="log-line"><span class="log-time">${new Date(p.time).toTimeString().slice(0,12)}</span> ` +
    `<span class="log-${p.act === 'PROPOSE' ? 'tx' : p.act === 'ACCEPT' ? 'rx' : p.act === 'REJECT' ? 'warn' : 'info'}">[${p.from}] ${p.act} topic=0x${p.topic.toString(16).padStart(4,'0')} "${p.content}"</span></div>`
  ).join('');
  el.scrollTop = el.scrollHeight;
}

function renderAgentCards() {
  const allAgents = [{ id: agentIdHex, role: negotiation.myRole, isSelf: true }];
  for (const [id, info] of negotiation.peers) {
    allAgents.push({ id, role: info.role, isSelf: false });
  }
  return allAgents.map(a => {
    const isPlaying = negotiation.state === 'PLAYING' && a.role;
    const cls = isPlaying ? 'singing' : a.isSelf ? 'listening' : '';
    const emoji = a.role ? (Conversations.ROLE_EMOJIS[a.role] || 'ðŸ¤–') : 'ðŸ¤–';
    const label = a.isSelf ? `You (${a.id.slice(0,8)})` : a.id.slice(0,8);
    return `<div class="agent-card ${cls}">
      <div class="agent-emoji">${emoji}</div>
      <div class="agent-name">${label}</div>
      <div class="agent-status" style="color:${a.role ? (Conversations.ROLE_COLORS[a.role] || 'var(--accent)') : 'var(--text2)'}">${a.role ? Conversations.ROLE_LABELS[a.role] || a.role : 'No role'}</div>
      <div class="agent-status">${isPlaying ? 'Transmitting' : a.isSelf ? negotiation.state : 'Peer'}</div>
    </div>`;
  }).join('');
}

function renderSinging() {
  const topics = Object.entries(Conversations.TOPICS);
  const isIdle = negotiation.state === 'IDLE';
  const isActive = !isIdle;
  return `
    <div class="card fade-in">
      <div class="card-title">ðŸ“¡ AILL Negotiation Protocol</div>
      <p style="color:var(--text2);font-size:13px;margin-bottom:16px;line-height:1.6">
        Distributed negotiation: devices discover each other, propose conversation topics via
        AILL PROPOSE/ACCEPT/REJECT messages, claim roles, then exchange data. Every sound is
        AILL wire-format data transmitted as acoustic tones â€” no human-readable audio.
      </p>
      <div style="display:flex;gap:12px;align-items:center;flex-wrap:wrap;margin-bottom:12px">
        <select id="songSelect" class="text-input" style="flex:0 0 200px" ${isActive ? 'disabled' : ''}>
          ${topics.map(([k,v]) => `<option value="${k}" ${k===negotiation.songKey?'selected':''}>${v.name}</option>`).join('')}
        </select>
        <button class="btn btn-primary" id="btnStartNeg" onclick="startNegotiation()" ${isActive ? 'disabled' : ''}>
          Start Negotiation
        </button>
        <button class="btn btn-danger" id="btnStopNeg" onclick="stopNegotiation()" ${isIdle ? 'disabled' : ''}>
          Stop
        </button>
        <div style="margin-left:auto;display:flex;align-items:center;gap:8px">
          <span style="font-family:var(--font-mono);font-size:11px;color:var(--text2)">State:</span>
          <span id="negStateLabel" style="font-family:var(--font-mono);font-size:12px;color:var(--accent);font-weight:600">${negotiation.state}</span>
        </div>
      </div>
      <div style="font-family:var(--font-mono);font-size:10px;color:var(--text2)">
        Agent ID: ${agentIdHex.slice(0,8)}...${agentIdHex.slice(-4)}
      </div>
    </div>

    <div class="agents-grid" id="agentsGrid">
      ${renderAgentCards()}
    </div>

    <div class="grid-2">
      <div class="card">
        <div class="card-title">Waveform</div>
        <div class="waveform-container">
          <canvas class="waveform-canvas" id="waveCanvas"></canvas>
          <div class="waveform-label">TIME DOMAIN</div>
        </div>
      </div>
      <div class="card">
        <div class="card-title">Spectrum</div>
        <div class="waveform-container">
          <canvas class="spectrum-canvas" id="specCanvas"></canvas>
          <div class="waveform-label">FREQUENCY DOMAIN</div>
        </div>
      </div>
    </div>

    <div class="card">
      <div class="card-title">Protocol Messages</div>
      <div class="log-console" id="protoLog" style="max-height:200px">
        ${negotiation.protocolLog.length === 0 ? '<span style="color:var(--text2)">No protocol messages yet</span>' : ''}
      </div>
    </div>

    <div class="card">
      <div class="card-title">Communication Log</div>
      <div class="log-console" id="logConsole"></div>
    </div>
  `;
}

// â”€â”€ Acoustic TX/RX helpers for negotiation â”€â”€

function negTransmit(wireData, label) {
  const ctx = ensureAudioCtx();
  if (AILL._hasAcousticWasm) {
    const pcm = AILL.acousticEncode(wireData, ctx.sampleRate);
    // Rust PCM has MASTER_GAIN=0.15 baked in; scale down further during playback
    const gainLevel = negotiation.state === 'PLAYING' ? 0.2 : 1.0;
    playPCM(ctx, pcm, ctx.sampleRate, gainLevel);
  } else {
    const tones = AILL.encodeToTones(wireData);
    const gain = negotiation.state === 'PLAYING' ? 0.03 : 0.15;
    AILL.playTones(ctx, tones, ctx.currentTime + 0.05, gain);
  }
  AILLBroadcast.send(wireData); // Also send via BroadcastChannel for same-device tabs
  addLog('tx', `TX ${wireData.length}B: ${label}`);
}

function negSendPragmatic(act, topicId, content) {
  const wire = AILL.encodePragmatic(act, topicId, content, agentId);
  const actNames = { 0x88: 'PROPOSE', 0x89: 'ACCEPT', 0x85: 'REJECT', 0x81: 'ASSERT' };
  const actName = actNames[act] || `0x${act.toString(16)}`;
  addProtoLog(agentIdHex, actName, topicId, content);
  negTransmit(wire, `${actName} topic=0x${topicId.toString(16).padStart(4,'0')} "${content.slice(0,40)}"`);
}

function handleNegotiationMessage(wireData) {
  const msg = AILL.decodePragmatic(wireData);
  if (!msg || !msg.act) return;

  // Self-echo mitigation: ignore messages from our own agent
  if (msg.agent === agentIdHex) return;

  addLog('rx', `RX [${msg.agent.slice(0,8)}] ${msg.act} topic=0x${msg.topic.toString(16).padStart(4,'0')} "${msg.content}"`);
  addProtoLog(msg.agent, msg.act, msg.topic, msg.content);

  // Update peer last-seen
  if (msg.agent) {
    if (!negotiation.peers.has(msg.agent)) {
      negotiation.peers.set(msg.agent, { songKey: null, role: null, lastSeen: Date.now() });
      addLog('info', `Discovered peer: ${msg.agent.slice(0,8)}`);
    }
    negotiation.peers.get(msg.agent).lastSeen = Date.now();
  }

  const st = negotiation.state;
  switch (msg.topic) {
    case NEG_TOPIC.SONG: // Song proposal/accept/reject
      if (msg.act === 'PROPOSE' && (st === 'DISCOVERY' || st === 'PROPOSING')) {
        // Peer proposed a song â€” compare UUIDs for tie-break
        const peerWins = msg.agent < agentIdHex; // lowest UUID wins
        if (peerWins) {
          negotiation.winningSong = msg.content;
          addLog('info', `Peer ${msg.agent.slice(0,8)} wins tie-break with "${msg.content}"`);
          negSendPragmatic(0x89, NEG_TOPIC.SONG, msg.content); // ACCEPT
          negSetState('ROLE_CLAIM');
          setTimeout(() => claimRole(), 500);
        } else {
          addLog('info', `We win tie-break against ${msg.agent.slice(0,8)}`);
          negSendPragmatic(0x85, NEG_TOPIC.SONG, negotiation.proposedSong); // REJECT (prefer ours)
        }
      } else if (msg.act === 'ACCEPT' && st === 'PROPOSING') {
        addLog('info', `Peer accepted our song proposal "${negotiation.proposedSong}"`);
        negotiation.winningSong = negotiation.proposedSong;
        negSetState('ROLE_CLAIM');
        setTimeout(() => claimRole(), 300);
      } else if (msg.act === 'REJECT' && st === 'PROPOSING') {
        addLog('info', `Peer rejected our proposal, waiting for their proposal...`);
        // Wait for their proposal to come (they should send PROPOSE next)
      }
      break;

    case NEG_TOPIC.ROLE: // Role claim
      if (msg.act === 'PROPOSE' && msg.content && msg.agent) {
        negotiation.peers.get(msg.agent).role = msg.content;
        addLog('info', `Peer ${msg.agent.slice(0,8)} claimed role: ${msg.content}`);
        updateNegUI();
      }
      break;

    case NEG_TOPIC.HEARTBEAT: // Heartbeat
      if (msg.act === 'ASSERT' && msg.content) {
        const parts = msg.content.split(':');
        if (parts.length >= 3 && msg.agent) {
          const peer = negotiation.peers.get(msg.agent);
          if (peer) {
            peer.songKey = parts[0];
            peer.role = parts[1];
            peer.lastSeen = Date.now();
          }
          // If we're discovering, we found an active song â€” join it
          if (st === 'DISCOVERY') {
            negotiation.winningSong = parts[0];
            addLog('info', `Detected active song "${parts[0]}" â€” joining`);
            negSetState('JOINING');
            negSetState('ROLE_CLAIM');
            setTimeout(() => claimRole(), 300);
          }
        }
      }
      break;
  }
}

// â”€â”€ Negotiation State Machine â”€â”€

async function startNegotiation() {
  negotiation.songKey = document.getElementById('songSelect')?.value || 'greeting';
  negotiation.peers.clear();
  negotiation.myRole = null;
  negotiation.proposedSong = null;
  negotiation.winningSong = null;
  negotiation.protocolLog = [];

  const btn = document.getElementById('btnStartNeg');
  const stopBtn = document.getElementById('btnStopNeg');
  if (btn) btn.disabled = true;
  if (stopBtn) stopBtn.disabled = false;

  addLog('info', 'â”€â”€â”€ Song Negotiation Started â”€â”€â”€');
  addLog('info', `Agent ID: ${agentIdHex.slice(0,8)}`);

  // Start listening for peer messages
  const micOk = await startNegotiationListener();

  // Phase 1: Discovery â€” listen for 2.5s
  negSetState('DISCOVERY');
  setStatus('DISCOVERING', 'var(--blue)');

  negotiation.discoveryTimer = setTimeout(() => {
    if (negotiation.state !== 'DISCOVERY') return;
    if (negotiation.peers.size === 0) {
      // No peers found â€” go solo
      addLog('info', 'No peers detected. Going solo.');
      negotiation.winningSong = negotiation.songKey;
      negSetState('CONFIRMED');
      setTimeout(() => {
        negSetState('ROLE_CLAIM');
        claimRole();
      }, 200);
    } else {
      // Peers found â€” propose our song
      proposeSong();
    }
  }, 2500);
}

function proposeSong() {
  negotiation.proposedSong = negotiation.songKey;
  negSetState('PROPOSING');
  setStatus('PROPOSING', 'var(--yellow)');

  negSendPragmatic(0x88, NEG_TOPIC.SONG, negotiation.proposedSong); // PROPOSE

  // Timeout: if no response in 3s, go solo
  negotiation.votingTimer = setTimeout(() => {
    if (negotiation.state === 'PROPOSING') {
      addLog('info', 'No peer response. Proceeding solo with our song.');
      negotiation.winningSong = negotiation.proposedSong;
      negSetState('ROLE_CLAIM');
      claimRole();
    }
  }, 3000);
}

function claimRole() {
  if (negotiation.state !== 'ROLE_CLAIM') return;
  setStatus('CLAIMING ROLE', 'var(--purple)');

  // Determine taken roles
  const takenRoles = new Set();
  for (const [, peer] of negotiation.peers) {
    if (peer.role) takenRoles.add(peer.role);
  }

  // Claim first available role from this topic's role list
  const topicKey = negotiation.winningSong || negotiation.songKey;
  const topic = Conversations.TOPICS[topicKey];
  const topicRoles = topic ? topic.roles : Conversations.ROLE_ORDER.slice(0, 4);
  const available = topicRoles.filter(r => !takenRoles.has(r));
  if (available.length === 0) {
    addLog('warn', 'All roles taken!');
    negotiation.myRole = topicRoles[0]; // fallback
  } else {
    negotiation.myRole = available[0];
  }

  addLog('info', `Claiming role: ${Conversations.ROLE_LABELS[negotiation.myRole] || negotiation.myRole}`);
  negSendPragmatic(0x88, NEG_TOPIC.ROLE, negotiation.myRole); // PROPOSE role

  updateNegUI();

  // Brief pause then start playing
  setTimeout(() => startPlaying(), 800);
}

function startPlaying() {
  const topicKey = negotiation.winningSong || negotiation.songKey;
  const topic = Conversations.TOPICS[topicKey];
  if (!topic) {
    addLog('warn', `Unknown topic: ${topicKey}`);
    stopNegotiation();
    return;
  }

  negSetState('PLAYING');
  setStatus('TRANSMITTING', 'var(--accent)');

  const role = negotiation.myRole;
  const msgGen = topic.messages[role];
  addLog('info', `Transmitting "${topic.name}" as ${Conversations.ROLE_LABELS[role] || role}`);

  // Start visualizations
  startVisualizations();

  // Transmit AILL data as acoustic tones every 2s
  // Each role sends its own type of AILL message
  let seq = 0;
  negotiation.heartbeatTimer = setInterval(() => {
    if (negotiation.state !== 'PLAYING') return;
    seq++;

    // Role-specific AILL data message
    if (msgGen) {
      const content = msgGen(seq);
      negSendPragmatic(0x81, NEG_TOPIC.HEARTBEAT, `${topicKey}:${role}:${content}`);
    } else {
      // Fallback heartbeat
      negSendPragmatic(0x81, NEG_TOPIC.HEARTBEAT, `${topicKey}:${role}:active seq=${seq}`);
    }
  }, 2000);

  // Send first message immediately
  if (msgGen) {
    const content = msgGen(0);
    negSendPragmatic(0x81, NEG_TOPIC.HEARTBEAT, `${topicKey}:${role}:${content}`);
  }

  // End after topic duration
  setTimeout(() => {
    if (negotiation.state === 'PLAYING') {
      addLog('info', 'â”€â”€â”€ Conversation Complete â”€â”€â”€');
      stopNegotiation();
    }
  }, topic.duration * 1000);
}

function stopNegotiation() {
  if (negotiation.heartbeatTimer) { clearInterval(negotiation.heartbeatTimer); negotiation.heartbeatTimer = null; }
  if (negotiation.discoveryTimer) { clearTimeout(negotiation.discoveryTimer); negotiation.discoveryTimer = null; }
  if (negotiation.votingTimer) { clearTimeout(negotiation.votingTimer); negotiation.votingTimer = null; }

  // Stop listening
  stopNegotiationListener();

  negotiation.state = 'IDLE';
  setStatus('IDLE', 'var(--accent)');
  stopVisualizations();

  const btn = document.getElementById('btnStartNeg');
  const stopBtn = document.getElementById('btnStopNeg');
  if (btn) btn.disabled = false;
  if (stopBtn) stopBtn.disabled = true;
  updateNegUI();
}

// â”€â”€ Negotiation Listener (wraps AILLReceiver) â”€â”€

let negListenerActive = false;

async function startNegotiationListener() {
  if (negListenerActive) return true;
  const ok = await AILLReceiver.start(
    // onReceive: try to decode as negotiation message
    (wireData, decoded) => {
      handleNegotiationMessage(wireData);
      // Also handle as content share if on that tab
      if (decoded && activeTab === 'share') {
        shareState.received.push({
          direction: 'rx', type: decoded.type || 'raw',
          content: decoded.content || '', bytes: wireData.length,
          source: 'mic', timestamp: Date.now()
        });
      }
    },
    (type, msg) => addLog(type, msg),
    (newState) => { /* mic state changes */ }
  );
  negListenerActive = ok;
  return ok;
}

function stopNegotiationListener() {
  if (negListenerActive) {
    AILLReceiver.stop();
    negListenerActive = false;
  }
}


// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// TAB: CONTENT SHARE
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

function renderShare() {
  const isListening = shareState.listening;
  const lState = shareState.listenerState;
  const dotClass = lState === 'RECEIVING' ? 'receiving' : isListening ? 'listening' : 'idle';
  const stateLabel = {
    'IDLE': 'Idle', 'LISTENING': 'Listening...', 'SYNC_RISING': 'Detecting chirp...',
    'SYNC_WAIT': 'Sync acquired', 'RECEIVING': 'Receiving data!'
  }[lState] || lState;

  const rxItems = shareState.received.filter(r => r.direction === 'rx');
  const txItems = shareState.received.filter(r => r.direction === 'tx');

  return `
    <div class="grid-2 fade-in">
      <div class="card">
        <div class="card-title">ðŸ“¡ Transmit</div>
        <p style="color:var(--text2);font-size:12px;margin-bottom:12px;line-height:1.5">
          Encode a message as AILL acoustic tones and play through speakers.
        </p>
        <div class="input-group">
          <input type="text" class="text-input" id="shareInput"
                 placeholder="URL or text message..." />
          <button class="btn btn-primary" id="btnTransmit" onclick="transmitContent()">
            ðŸ“¡ Send
          </button>
        </div>
        <div id="txProgress" style="display:none">
          <div style="font-size:12px;color:var(--text2);margin:8px 0">Transmitting...</div>
          <div class="tx-progress"><div class="tx-progress-bar" id="txBar" style="width:0%"></div></div>
        </div>
        <div id="transmittedList" style="margin-top:12px">
          ${txItems.map(r => `
            <div class="received-content">
              <div class="content-type">Sent: ${r.type} <span class="rx-badge local">speaker</span></div>
              <div class="content-body">${escapeHtml(r.content)}</div>
              <div style="font-size:10px;color:var(--text2);margin-top:6px;font-family:var(--font-mono)">${r.bytes}B | ${r.duration}s</div>
            </div>
          `).join('') || '<div style="color:var(--text2);font-size:12px;margin-top:8px">No transmissions yet</div>'}
        </div>
      </div>

      <div class="card">
        <div class="card-title">ðŸŽ™ Receive</div>
        <p style="color:var(--text2);font-size:12px;margin-bottom:12px;line-height:1.5">
          Listen via microphone for AILL transmissions from nearby devices.
        </p>
        <div style="display:flex;gap:8px;align-items:center">
          <button class="btn ${isListening ? 'btn-danger' : 'btn-primary'}" id="btnListen"
                  onclick="${isListening ? 'stopListeningMode()' : 'startListeningMode()'}">
            ${isListening ? 'â—¼ Stop Listening' : 'ðŸŽ™ Start Listening'}
          </button>
        </div>
        <div class="listen-status">
          <div class="listen-dot ${dotClass}"></div>
          <span style="color:${isListening ? 'var(--accent)' : 'var(--text2)'}">${stateLabel}</span>
          ${isListening ? `<span style="margin-left:auto;font-size:10px;color:var(--text2)">MIC ON</span>` : ''}
        </div>
        ${isListening ? `
        <div class="waveform-container" style="margin-bottom:12px">
          <canvas class="mic-spectrum-canvas" id="micSpecCanvas"></canvas>
          <div class="waveform-label">MICROPHONE INPUT</div>
        </div>` : ''}
        <div id="receivedList">
          ${rxItems.map(r => `
            <div class="received-content">
              <div class="content-type">Received: ${r.type || 'data'} <span class="rx-badge ${r.source === 'mic' ? 'acoustic' : r.source === 'broadcast' ? 'broadcast' : 'local'}">${r.source === 'mic' ? 'acoustic' : r.source === 'broadcast' ? 'broadcast' : 'local'}</span></div>
              <div class="content-body">${r.type === 'url' ? `<a href="${escapeHtml(r.content)}" target="_blank">${escapeHtml(r.content)}</a>` : escapeHtml(r.content)}</div>
              <div style="font-size:10px;color:var(--text2);margin-top:6px;font-family:var(--font-mono)">${r.bytes}B decoded</div>
            </div>
          `).join('') || `<div style="color:var(--text2);font-size:12px;margin-top:8px">${isListening ? 'Waiting for signal...' : 'Start listening to receive'}</div>`}
        </div>
      </div>
    </div>

    <div class="grid-2">
      <div class="card">
        <div class="card-title">Speaker Output</div>
        <div class="waveform-container">
          <canvas class="waveform-canvas" id="waveCanvas"></canvas>
          <div class="waveform-label">TX WAVEFORM</div>
        </div>
      </div>
      <div class="card">
        <div class="card-title">Spectrum</div>
        <div class="waveform-container">
          <canvas class="spectrum-canvas" id="specCanvas"></canvas>
          <div class="waveform-label">FREQUENCY DOMAIN</div>
        </div>
      </div>
    </div>

    <div class="card">
      <div class="card-title">ðŸ“‹ Communication Log</div>
      <div class="log-console" id="logConsole"></div>
    </div>
  `;
}

function escapeHtml(str) {
  const d = document.createElement('div');
  d.textContent = str;
  return d.innerHTML;
}

async function startListeningMode() {
  shareState.listening = true;
  shareState.listenerState = 'LISTENING';
  setStatus('LISTENING', 'var(--blue)');
  renderTab();

  const ok = await AILLReceiver.start(
    // onReceive
    (wireData, decoded) => {
      const content = decoded?.content || Array.from(wireData.slice(0, 32)).map(b => b.toString(16).padStart(2, '0')).join(' ');
      const type = decoded?.type || 'raw';
      shareState.received.push({
        direction: 'rx', type, content,
        bytes: wireData.length,
        source: 'mic',
        timestamp: Date.now()
      });
      renderTab();
    },
    // onLog
    (type, msg) => addLog(type, msg),
    // onStateChange
    (newState) => {
      shareState.listenerState = newState;
      // Update the status dot and label without full re-render
      const dot = document.querySelector('.listen-dot');
      const label = document.querySelector('.listen-status span');
      if (dot) {
        dot.className = 'listen-dot ' + (newState === 'RECEIVING' ? 'receiving' : 'listening');
      }
      if (label) {
        const stateLabel = {
          'LISTENING': 'Listening...', 'SYNC_RISING': 'Detecting chirp...',
          'SYNC_WAIT': 'Sync acquired', 'RECEIVING': 'Receiving data!'
        }[newState] || newState;
        label.textContent = stateLabel;
        label.style.color = newState === 'RECEIVING' ? 'var(--accent)' : 'var(--blue)';
      }
      if (newState === 'RECEIVING') {
        setStatus('RECEIVING', 'var(--accent)');
      } else if (newState === 'LISTENING') {
        setStatus('LISTENING', 'var(--blue)');
      }
    }
  );

  if (!ok) {
    shareState.listening = false;
    shareState.listenerState = 'IDLE';
    setStatus('IDLE', 'var(--accent)');
    renderTab();
    return;
  }

  // Start mic spectrum visualization
  startMicSpectrum();
}

function stopListeningMode() {
  AILLReceiver.stop();
  shareState.listening = false;
  shareState.listenerState = 'IDLE';
  setStatus('IDLE', 'var(--accent)');
  if (micSpectrumAnimId) { cancelAnimationFrame(micSpectrumAnimId); micSpectrumAnimId = null; }
  renderTab();
}

function startMicSpectrum() {
  const rxAnalyser = AILLReceiver.getAnalyser();
  const rxCtx = AILLReceiver.getCtx();
  if (!rxAnalyser || !rxCtx) return;

  function draw() {
    const canvas = document.getElementById('micSpecCanvas');
    if (!canvas || !shareState.listening) { micSpectrumAnimId = null; return; }
    micSpectrumAnimId = requestAnimationFrame(draw);

    const ctx2d = canvas.getContext('2d');
    canvas.width = canvas.offsetWidth * 2;
    canvas.height = canvas.offsetHeight * 2;
    const w = canvas.width, h = canvas.height;

    const bufLen = rxAnalyser.frequencyBinCount;
    const data = new Uint8Array(bufLen);
    rxAnalyser.getByteFrequencyData(data);

    ctx2d.fillStyle = '#0a0c10';
    ctx2d.fillRect(0, 0, w, h);

    // Show 0-2200Hz range (covers all AILL tones)
    const maxBin = Math.floor(2200 / (rxCtx.sampleRate / rxAnalyser.fftSize));
    const barW = w / maxBin;

    for (let i = 0; i < maxBin; i++) {
      const val = data[i] / 255;
      const barH = val * h;
      const freq = i * rxCtx.sampleRate / rxAnalyser.fftSize;

      // Highlight AILL tone frequencies (600-1300Hz)
      let hue, sat;
      if (freq >= 580 && freq <= 1320) {
        hue = 165; sat = 90; // teal â€” signal band
      } else if (freq >= 250 && freq <= 550) {
        hue = 45; sat = 80; // amber â€” sync band
      } else {
        hue = 220; sat = 30; // dim blue â€” noise
      }

      ctx2d.fillStyle = `hsla(${hue}, ${sat}%, ${35 + val * 35}%, ${0.3 + val * 0.7})`;
      ctx2d.fillRect(i * barW, h - barH, barW - 1, barH);
    }

    // Frequency labels
    ctx2d.fillStyle = 'rgba(255,255,255,0.2)';
    ctx2d.font = '14px JetBrains Mono';
    [300, 600, 900, 1200, 1500, 1800].forEach(f => {
      const x = (f / 2200) * w;
      ctx2d.fillText(`${f}`, x, h - 4);
    });

    // Mark AILL tone band
    const bandL = (580 / 2200) * w, bandR = (1320 / 2200) * w;
    ctx2d.strokeStyle = 'rgba(0,212,170,0.25)';
    ctx2d.lineWidth = 1;
    ctx2d.setLineDash([4, 4]);
    ctx2d.beginPath();
    ctx2d.moveTo(bandL, 0); ctx2d.lineTo(bandL, h);
    ctx2d.moveTo(bandR, 0); ctx2d.lineTo(bandR, h);
    ctx2d.stroke();
    ctx2d.setLineDash([]);
  }
  draw();
}

async function transmitContent() {
  const input = document.getElementById('shareInput');
  const content = input.value.trim();
  if (!content) return;

  const ctx = ensureAudioCtx();
  const isURL = /^https?:\/\//i.test(content);
  const type = isURL ? 'url' : 'text';

  // Encode
  const wire = isURL ? AILL.encodeURL(content) : AILL.encodeContent('text', content);
  const duration = AILL._hasAcousticWasm
    ? AILL.acousticDuration(wire.length)
    : AILL.calcDuration(wire);

  addLog('info', `â”€â”€â”€ Transmitting: ${type.toUpperCase()} â”€â”€â”€`);
  addLog('tx', `Encoding ${content.length} chars â†’ ${wire.length} bytes wire format`);
  addLog('tx', `CRC-8: 0x${AILL.crc8(wire).toString(16).toUpperCase().padStart(2,'0')}`);
  addLog('tx', `${duration.toFixed(2)}s duration`);
  addLog('tx', `Playing acoustic signal...`);

  // Show progress
  const prog = document.getElementById('txProgress');
  const bar = document.getElementById('txBar');
  if (prog) prog.style.display = 'block';

  setStatus('TRANSMITTING', 'var(--yellow)');
  const btn = document.getElementById('btnTransmit');
  if (btn) btn.disabled = true;

  // Play the tones through speakers + broadcast to other tabs
  if (AILL._hasAcousticWasm) {
    const pcm = AILL.acousticEncode(wire, ctx.sampleRate);
    playPCM(ctx, pcm, ctx.sampleRate);
  } else {
    const tones = AILL.encodeToTones(wire);
    AILL.playTones(ctx, tones, ctx.currentTime + 0.05, 0.15);
  }
  AILLBroadcast.send(wire);
  startVisualizations();

  // Animate progress
  const startMs = Date.now();
  const totalMs = duration * 1000;
  const animProg = () => {
    const elapsed = Date.now() - startMs;
    const pct = Math.min(100, (elapsed / totalMs) * 100);
    if (bar) bar.style.width = pct + '%';
    if (pct < 100) requestAnimationFrame(animProg);
  };
  animProg();

  // Record transmission
  shareState.received.push({
    direction: 'tx', type, content,
    bytes: wire.length, duration: duration.toFixed(2),
    timestamp: Date.now()
  });

  // Clean up after transmission completes
  setTimeout(() => {
    addLog('tx', `Transmission complete (${wire.length} bytes sent)`);
    setStatus(shareState.listening ? 'LISTENING' : 'IDLE', shareState.listening ? 'var(--blue)' : 'var(--accent)');
    if (prog) prog.style.display = 'none';
    if (btn) btn.disabled = false;
    input.value = '';
    renderTab();
    setTimeout(() => stopVisualizations(), 500);
  }, totalMs + 200);
}


// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// TAB: PROTOCOL INSPECTOR
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

function renderInspector() {
  // Build some example utterances
  const examples = [
    { label: 'Position Report', wire: AILL.encodeContent('nav_position', '{"x":12.5,"y":-3.8,"z":2.1}') },
    { label: 'Battery Query', wire: AILL.encodeString('QUERY:battery_level') },
    { label: 'URL Share', wire: AILL.encodeURL('https://example.com/ai-research') },
    { label: 'Greeting', wire: AILL.encodeString('GREET:Hello from Agent Alpha') },
  ];

  return `
    <div class="card fade-in">
      <div class="card-title">ðŸ”¬ AILL Protocol Inspector</div>
      <p style="color:var(--text2);font-size:13px;margin-bottom:16px;line-height:1.6">
        Examine the wire format of AILL utterances. Select an example or enter custom text
        to see how AILL encodes data at the byte level, including the codebook lookups.
      </p>
      <div class="input-group">
        <input type="text" class="text-input" id="inspectInput"
               placeholder="Enter text to encode as AILL..." value="Hello, World!" />
        <button class="btn btn-primary" onclick="inspectEncode()">Encode</button>
        <button class="btn" onclick="inspectPlay()">ðŸ”Š Play</button>
      </div>
    </div>

    <div class="grid-2">
      <div class="card">
        <div class="card-title">Wire Format (Hex)</div>
        <div class="hex-view" id="hexView">
          <span class="hex-data">Click "Encode" to generate wire format...</span>
        </div>
      </div>
      <div class="card">
        <div class="card-title">Decoded AST</div>
        <div class="log-console" id="astView" style="font-size:12px">
          Click "Encode" to decode...
        </div>
      </div>
    </div>

    <div class="card">
      <div class="card-title">Example Utterances</div>
      <div style="display:grid;grid-template-columns:repeat(auto-fill,minmax(280px,1fr));gap:12px">
        ${examples.map((ex, i) => `
          <div class="received-content" style="cursor:pointer" onclick="loadExample(${i})">
            <div class="content-type">${ex.label}</div>
            <div style="font-family:var(--font-mono);font-size:11px;color:var(--text2)">
              ${ex.wire.length} bytes | CRC: 0x${AILL.crc8(ex.wire).toString(16).toUpperCase().padStart(2,'0')}
            </div>
            <div style="font-family:var(--font-mono);font-size:10px;color:var(--accent);margin-top:6px;word-break:break-all">
              ${Array.from(ex.wire.slice(0, 24)).map(b => b.toString(16).padStart(2,'0')).join(' ')}${ex.wire.length > 24 ? ' ...' : ''}
            </div>
          </div>
        `).join('')}
      </div>
    </div>

    <div class="card">
      <div class="card-title">Base Codebook Reference</div>
      <div style="display:grid;grid-template-columns:repeat(auto-fill,minmax(180px,1fr));gap:4px;font-family:var(--font-mono);font-size:11px">
        ${Object.entries(AILL.MNEMONICS).map(([code, name]) => `
          <div style="padding:4px 8px;background:var(--bg);border-radius:4px;display:flex;justify-content:space-between">
            <span style="color:var(--accent)">0x${parseInt(code).toString(16).toUpperCase().padStart(2,'0')}</span>
            <span style="color:var(--text2)">${name}</span>
          </div>
        `).join('')}
      </div>
    </div>

    <div class="card">
      <div class="card-title">Waveform Preview</div>
      <div class="waveform-container">
        <canvas class="waveform-canvas" id="waveCanvas"></canvas>
        <div class="waveform-label">ACOUSTIC OUTPUT</div>
      </div>
    </div>
  `;
}

const INSPECT_EXAMPLES = [
  { text: '{"x":12.5,"y":-3.8,"z":2.1}', type: 'nav_position' },
  { text: 'QUERY:battery_level', type: null },
  { text: 'https://example.com/ai-research', type: null },
  { text: 'GREET:Hello from Agent Alpha', type: null },
];

function loadExample(idx) {
  const ex = INSPECT_EXAMPLES[idx];
  const input = document.getElementById('inspectInput');
  if (input) {
    input.value = ex.text;
    inspectEncode();
  }
}

function inspectEncode() {
  const input = document.getElementById('inspectInput');
  const text = input ? input.value.trim() : '';
  if (!text) return;

  const isURL = /^https?:\/\//i.test(text);
  const wire = isURL ? AILL.encodeURL(text) : AILL.encodeString(text);

  // Hex view
  const hexEl = document.getElementById('hexView');
  if (hexEl) hexEl.innerHTML = AILL.hexDump(wire);

  // AST view
  const astEl = document.getElementById('astView');
  if (astEl) {
    const lines = [];
    lines.push(`<span style="color:var(--accent)">Utterance</span> (${wire.length} bytes, CRC-8: 0x${AILL.crc8(wire).toString(16).toUpperCase().padStart(2,'0')})`);
    lines.push('');
    // Walk through bytes and annotate
    let pos = 0;
    while (pos < wire.length) {
      const byte = wire[pos];
      const mnem = AILL.MNEMONICS[byte];
      if (mnem) {
        lines.push(`  <span style="color:var(--blue)">0x${byte.toString(16).padStart(2,'0')}</span>  <span style="color:var(--accent)">${mnem}</span>`);
      } else if (byte >= 0x20 && byte < 0x7F) {
        lines.push(`  <span style="color:var(--blue)">0x${byte.toString(16).padStart(2,'0')}</span>  <span style="color:var(--text2)">'${String.fromCharCode(byte)}'</span>`);
      } else {
        lines.push(`  <span style="color:var(--blue)">0x${byte.toString(16).padStart(2,'0')}</span>  <span style="color:var(--text2)">data</span>`);
      }
      pos++;
    }
    astEl.innerHTML = lines.join('\n');
  }
}

function inspectPlay() {
  const input = document.getElementById('inspectInput');
  const text = input ? input.value.trim() : '';
  if (!text) return;

  const ctx = ensureAudioCtx();
  const isURL = /^https?:\/\//i.test(text);
  const wire = isURL ? AILL.encodeURL(text) : AILL.encodeString(text);

  let duration;
  if (AILL._hasAcousticWasm) {
    const pcm = AILL.acousticEncode(wire, ctx.sampleRate);
    playPCM(ctx, pcm, ctx.sampleRate, 0.67);
    duration = AILL.acousticDuration(wire.length);
  } else {
    const tones = AILL.encodeToTones(wire);
    AILL.playTones(ctx, tones, ctx.currentTime + 0.05, 0.1);
    duration = AILL.calcDuration(wire);
  }
  AILLBroadcast.send(wire);
  startVisualizations();
  setTimeout(() => stopVisualizations(), duration * 1000 + 500);
}


// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// VISUALIZATIONS
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

function startVisualizations() {
  if (!audioCtx || !analyser) return;
  drawWaveform();
  drawSpectrum();
}

function stopVisualizations() {
  if (waveformAnimId) cancelAnimationFrame(waveformAnimId);
  if (spectrumAnimId) cancelAnimationFrame(spectrumAnimId);
  waveformAnimId = null;
  spectrumAnimId = null;
}

function drawWaveform() {
  const canvas = document.getElementById('waveCanvas');
  if (!canvas || !analyser) return;
  const ctx2d = canvas.getContext('2d');
  canvas.width = canvas.offsetWidth * 2;
  canvas.height = canvas.offsetHeight * 2;
  const w = canvas.width, h = canvas.height;
  const bufLen = analyser.frequencyBinCount;
  const data = new Uint8Array(bufLen);

  function draw() {
    waveformAnimId = requestAnimationFrame(draw);
    analyser.getByteTimeDomainData(data);
    ctx2d.fillStyle = '#0a0c10';
    ctx2d.fillRect(0, 0, w, h);
    ctx2d.lineWidth = 2;
    ctx2d.strokeStyle = '#00d4aa';
    ctx2d.beginPath();
    const sliceW = w / bufLen;
    for (let i = 0; i < bufLen; i++) {
      const v = data[i] / 128.0;
      const y = v * h / 2;
      if (i === 0) ctx2d.moveTo(0, y);
      else ctx2d.lineTo(i * sliceW, y);
    }
    ctx2d.stroke();
    // Glow effect
    ctx2d.lineWidth = 6;
    ctx2d.strokeStyle = 'rgba(0,212,170,0.15)';
    ctx2d.beginPath();
    for (let i = 0; i < bufLen; i++) {
      const v = data[i] / 128.0;
      const y = v * h / 2;
      if (i === 0) ctx2d.moveTo(0, y);
      else ctx2d.lineTo(i * sliceW, y);
    }
    ctx2d.stroke();
  }
  draw();
}

function drawSpectrum() {
  const canvas = document.getElementById('specCanvas');
  if (!canvas || !analyser) return;
  const ctx2d = canvas.getContext('2d');
  canvas.width = canvas.offsetWidth * 2;
  canvas.height = canvas.offsetHeight * 2;
  const w = canvas.width, h = canvas.height;
  const bufLen = analyser.frequencyBinCount;
  const data = new Uint8Array(bufLen);

  function draw() {
    spectrumAnimId = requestAnimationFrame(draw);
    analyser.getByteFrequencyData(data);
    ctx2d.fillStyle = '#0a0c10';
    ctx2d.fillRect(0, 0, w, h);
    // Only show up to ~4kHz (relevant AILL range)
    const maxBin = Math.floor(4000 / (audioCtx.sampleRate / analyser.fftSize));
    const barW = w / maxBin;
    for (let i = 0; i < maxBin; i++) {
      const val = data[i] / 255;
      const barH = val * h;
      const hue = 165 + val * 40; // teal to green
      ctx2d.fillStyle = `hsla(${hue}, 80%, ${40 + val * 30}%, ${0.4 + val * 0.6})`;
      ctx2d.fillRect(i * barW, h - barH, barW - 1, barH);
      // Glow
      if (val > 0.3) {
        ctx2d.fillStyle = `hsla(${hue}, 80%, 60%, ${val * 0.2})`;
        ctx2d.fillRect(i * barW - 2, h - barH - 4, barW + 3, barH + 8);
      }
    }
    // Frequency labels
    ctx2d.fillStyle = 'rgba(255,255,255,0.2)';
    ctx2d.font = '16px JetBrains Mono';
    for (let f = 500; f <= 3500; f += 500) {
      const x = (f / 4000) * w;
      ctx2d.fillText(`${f}Hz`, x, h - 4);
    }
  }
  draw();
}


// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// TAB ROUTING
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

function renderTab() {
  const main = document.getElementById('mainContent');
  stopVisualizations();
  if (micSpectrumAnimId) { cancelAnimationFrame(micSpectrumAnimId); micSpectrumAnimId = null; }
  if (activeTab === 'singing') main.innerHTML = renderSinging();
  else if (activeTab === 'share') {
    main.innerHTML = renderShare();
    if (shareState.listening) startMicSpectrum();
  }
  else if (activeTab === 'inspector') main.innerHTML = renderInspector();
  updateLogConsole();
}

document.getElementById('tabs').addEventListener('click', (e) => {
  const tab = e.target.closest('.tab');
  if (!tab) return;
  document.querySelectorAll('.tab').forEach(t => t.classList.remove('active'));
  tab.classList.add('active');
  activeTab = tab.dataset.tab;
  renderTab();
});

// â”€â”€ Initialize BroadcastChannel for same-device tab-to-tab communication â”€â”€
AILLBroadcast.init((wireData, source) => {
  addLog('rx', `Broadcast RX: ${wireData.length} bytes from another tab`);

  // Decode and route the message
  const decoded = AILL.decode(wireData);

  // Route to Content Share receive list
  if (decoded) {
    shareState.received.push({
      direction: 'rx', type: decoded.type || 'data',
      content: decoded.content || '', bytes: wireData.length,
      source: 'broadcast', timestamp: Date.now()
    });
  }

  // Route to negotiation handler
  handleNegotiationMessage(wireData);

  if (activeTab === 'share' || activeTab === 'singing') renderTab();
});

// Initial render
addLog('info', 'AILL v1.1 Reference Implementation initialized');
addLog('info', 'Web Audio API ready. Select a mode to begin.');
renderTab();
</script>

<script type="module">
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// WASM Integration â€” patches AILL with spec-compliant Rust implementation
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
import init, {
  encode_string, encode_url, encode_content,
  decode_simple, decode_ast, pretty_print_bytes,
  crc8_compute, hex_dump, get_mnemonics, mnemonic_for,
  validate_epoch,
  encode_pragmatic, encode_task_allocation, decode_pragmatic_simple,
  acoustic_encode, acoustic_decode, acoustic_duration
} from './pkg/aill.js';

try {
  await init();

  // Patch protocol functions with spec-compliant WASM implementations
  AILL.encodeString = (msg) => encode_string(msg);
  AILL.encodeURL = (url) => encode_url(url);
  AILL.encodeContent = (type, content) => encode_content(type, content);
  AILL.decode = (bytes) => {
    try {
      const data = bytes instanceof Uint8Array ? bytes : new Uint8Array(bytes);
      return decode_simple(data);
    } catch(e) { return null; }
  };
  AILL.crc8 = (data) => {
    const arr = data instanceof Uint8Array ? data : new Uint8Array(data);
    return crc8_compute(arr);
  };
  AILL.hexDump = (data, maxBytes = 128) => {
    const arr = data instanceof Uint8Array ? data : new Uint8Array(data);
    return hex_dump(arr, maxBytes);
  };
  AILL.MNEMONICS = get_mnemonics();

  // Add WASM-only functions
  AILL.prettyPrint = (data) => {
    const arr = data instanceof Uint8Array ? data : new Uint8Array(data);
    return pretty_print_bytes(arr);
  };
  AILL.decodeAST = (data) => {
    const arr = data instanceof Uint8Array ? data : new Uint8Array(data);
    return decode_ast(arr);
  };
  AILL.mnemonicFor = mnemonic_for;
  AILL.validateEpoch = (data) => {
    const arr = data instanceof Uint8Array ? data : new Uint8Array(data);
    return validate_epoch(arr);
  };

  // Negotiation protocol functions (WASM-only â€” no JS fallback needed)
  AILL.encodePragmatic = (act, topic, content, agentIdArr) => {
    const id = agentIdArr instanceof Uint8Array ? agentIdArr : new Uint8Array(agentIdArr);
    return encode_pragmatic(act, topic, content, id);
  };
  AILL.encodeTaskAllocation = (taskId, role, agentIdArr) => {
    const id = agentIdArr instanceof Uint8Array ? agentIdArr : new Uint8Array(agentIdArr);
    return encode_task_allocation(taskId, role, id);
  };
  AILL.decodePragmatic = (data) => {
    const arr = data instanceof Uint8Array ? data : new Uint8Array(data);
    return decode_pragmatic_simple(arr);
  };

  // Acoustic encoder/decoder (WASM â€” replaces JS oscillator-based encoding)
  if (typeof acoustic_encode === 'function') {
    AILL.acousticEncode = (wireData, sr) => acoustic_encode(
      wireData instanceof Uint8Array ? wireData : new Uint8Array(wireData), sr || 0);
    AILL.acousticDecode = (samples, sr) => acoustic_decode(
      samples instanceof Float32Array ? samples : new Float32Array(samples), sr || 0);
    AILL.acousticDuration = acoustic_duration;
    AILL._hasAcousticWasm = true;
    addLog('info', 'WASM acoustic encoder/decoder loaded');
  }

  // Enhance Protocol Inspector with real AST pretty-printer
  window.inspectEncode = function() {
    const input = document.getElementById('inspectInput');
    const text = input ? input.value.trim() : '';
    if (!text) return;

    const isURL = /^https?:\/\//i.test(text);
    const wire = isURL ? AILL.encodeURL(text) : AILL.encodeString(text);

    // Hex view (WASM)
    const hexEl = document.getElementById('hexView');
    if (hexEl) hexEl.innerHTML = AILL.hexDump(wire);

    // AST view â€” use real spec-compliant pretty-printer
    const astEl = document.getElementById('astView');
    if (astEl) {
      try {
        const prettyText = AILL.prettyPrint(wire);
        const crcVal = AILL.crc8(wire);
        const header = `<span style="color:var(--accent)">AILL Wire Format</span> (${wire.length} bytes, CRC-8: 0x${crcVal.toString(16).toUpperCase().padStart(2,'0')})\n\n`;
        // Syntax-highlight the pretty-printed AST
        const highlighted = prettyText
          .replace(/^(\s*)(UTTERANCE|ASSERT|QUERY|COMMAND|REQUEST|WARN|ACKNOWLEDGE|GREET|FAREWELL|PROPOSE|ACCEPT|REJECT)/gm,
            '$1<span style="color:var(--accent)">$2</span>')
          .replace(/^(\s*)(STRUCT|LIST|MAP|FIELD_ID|BEGIN_\w+|END_\w+)/gm,
            '$1<span style="color:var(--yellow)">$2</span>')
          .replace(/^(\s*)(OBSERVED|INFERRED|PREDICTED|CERTAIN|PROBABLE|POSSIBLE)/gm,
            '$1<span style="color:var(--blue)">$2</span>')
          .replace(/^(\s*)(PAST|PRESENT|FUTURE)/gm,
            '$1<span style="color:var(--blue)">$2</span>')
          .replace(/(confidence|priority|timestamp|meta)/gi,
            '<span style="color:var(--text2)">$1</span>')
          .replace(/("(?:[^"\\]|\\.)*")/g,
            '<span style="color:#98c379">$1</span>')
          .replace(/\b(\d+(?:\.\d+)?)\b/g,
            '<span style="color:#d19a66">$1</span>');
        astEl.innerHTML = header + highlighted;
      } catch(e) {
        // Fallback to byte-by-byte annotation
        const lines = [];
        lines.push(`<span style="color:var(--accent)">Utterance</span> (${wire.length} bytes, CRC-8: 0x${AILL.crc8(wire).toString(16).toUpperCase().padStart(2,'0')})`);
        lines.push('');
        let pos = 0;
        while (pos < wire.length) {
          const byte = wire[pos];
          const mnem = AILL.MNEMONICS[byte];
          if (mnem) {
            lines.push(`  <span style="color:var(--blue)">0x${byte.toString(16).padStart(2,'0')}</span>  <span style="color:var(--accent)">${mnem}</span>`);
          } else {
            lines.push(`  <span style="color:var(--blue)">0x${byte.toString(16).padStart(2,'0')}</span>  <span style="color:var(--text2)">data</span>`);
          }
          pos++;
        }
        astEl.innerHTML = lines.join('\n');
      }
    }
  };

  addLog('info', 'WASM module loaded â€” using spec-compliant Rust encoder/decoder');
  // Re-render to pick up WASM MNEMONICS if on inspector tab
  if (activeTab === 'inspector') renderTab();

} catch(e) {
  console.warn('WASM load failed, using JS fallback:', e);
  addLog('warn', 'WASM unavailable â€” using JS fallback encoder/decoder');
}
</script>
</body>
</html>
